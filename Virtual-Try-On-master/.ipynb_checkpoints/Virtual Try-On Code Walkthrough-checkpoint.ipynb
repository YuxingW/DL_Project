{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "print(h5py.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPVTON\n",
      "LIPJPPNET\n",
      "Importing data\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matlab.engine\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "print(\"CPVTON\")\n",
    "sys.path.append('./cp_vton')\n",
    "\n",
    "print(\"LIPJPPNET\")\n",
    "sys.path.append('./LIP_JPPNet')\n",
    "\n",
    "print(\"Importing data\")\n",
    "from LIP_JPPNet.evaluate_parsing_JPPNet import *\n",
    "from cp_vton.test import *\n",
    "FINE_HEIGHT = 256\n",
    "FINE_WIDTH = 192\n",
    "POINT_NUM = 18\n",
    "\n",
    "class opt():\n",
    "    def __init__(self, name, stage, data_path, imname, cname, result_dir, checkpoint):\n",
    "        self.name = name\n",
    "        self.gpu_ids = \"\"\n",
    "        self.workers = 0\n",
    "        self.batch_size = 4\n",
    "        self.data_path = data_path\n",
    "        self.stage = stage\n",
    "        self.imname = imname\n",
    "        self.cname = cname\n",
    "        self.fine_width = 192\n",
    "        self.fine_height = 256\n",
    "        self.radius = 5\n",
    "        self.grid_size = 5\n",
    "        self.grid_image = 'cp_vton/grid.png'\n",
    "        self.result_dir = result_dir\n",
    "        self.checkpoint = checkpoint\n",
    "        self.shuffle = False\n",
    "\n",
    "def create_dir(target_root_dir):\n",
    "    if not os.path.exists(target_root_dir):\n",
    "        os.makedirs(target_root_dir)\n",
    "    dir_list = ['cloth', 'cloth-mask', 'image', 'image-parse', 'pose']\n",
    "    for dir in dir_list:\n",
    "        full_dir = os.path.join(target_root_dir, dir)\n",
    "        if not os.path.exists(full_dir):\n",
    "            os.makedirs(full_dir)\n",
    "\n",
    "\n",
    "def run_mat(source_root_dir, target_root_dir, imname, cname):\n",
    "    eng = matlab.engine.start_matlab()\n",
    "    eng.convert_data(source_root_dir, target_root_dir, imname, cname, FINE_HEIGHT, FINE_WIDTH)\n",
    "    eng.quit()\n",
    "\n",
    "\n",
    "def convert_keypoints(source_root_dir, target_root_dir, imname):\n",
    "        # load image\n",
    "        im = cv2.imread(source_root_dir + 'image/' + imname)\n",
    "        h = im.shape[0]\n",
    "        w = im.shape[1]\n",
    "        # load keypoints\n",
    "        key_name = imname[:-4] + '_keypoints.json'\n",
    "        with open(source_root_dir + 'pose/' + key_name, 'r') as rf:\n",
    "            pose = json.load(rf)\n",
    "        key_points = pose['people'][0]['pose_keypoints_2d']\n",
    "\n",
    "        for i in range(POINT_NUM):\n",
    "            key_points[3 * i] = key_points[3 * i] / w * FINE_WIDTH\n",
    "            key_points[3 * i + 1] = key_points[3 * i + 1] / h * FINE_HEIGHT\n",
    "\n",
    "        pose = {\"version\": 1.0, \"people\": [\n",
    "            {\"face_keypoints\": [], \"pose_keypoints\": key_points, \"hand_right_keypoints\": [],\n",
    "             \"hand_left_keypoints\": []}]}\n",
    "        with open(target_root_dir + 'pose/' + key_name, 'w') as wf:\n",
    "            json.dump(pose, wf)\n",
    "\n",
    "\n",
    "def main(source_root_dir, target_root_dir, imname, cname):\n",
    "    # get pose\n",
    "    #os.system(\"OpenPose\\\\bin\\OpenPoseDemo.exe --image_dir data\\image\\\\ --model_folder OpenPose\\models\"\")\n",
    "    create_dir(target_root_dir)\n",
    "    print(\"Running matlab\")\n",
    "    run_mat(source_root_dir, target_root_dir, imname, cname)\n",
    "    print(\"Converting keypoints\")\n",
    "    convert_keypoints(source_root_dir, target_root_dir, imname)\n",
    "    # get segment\n",
    "    print(\"JNet Parsing\")\n",
    "    JPPNet_parsing(target_root_dir + 'image/' + imname, checkpoint_dir='LIP_JPPNet/checkpoint/JPPNet-s2', output_dir='data/test/image-parse/')\n",
    "    # run cp-vton\n",
    "    print(\"GMM\")\n",
    "    gmm_opt = opt(name=\"gmm_traintest_new\", stage=\"GMM\", data_path='data/test', result_dir='data/test', imname=imname, cname=cname, checkpoint='cp_vton/checkpoints/gmm_train_new/gmm_final.pth')\n",
    "    inference(gmm_opt)\n",
    "    print(\"TOM\")\n",
    "    tom_opt = opt(name=\"tom_test_new\", stage=\"TOM\", data_path='data/test', result_dir='result', imname=imname, cname=cname, checkpoint='cp_vton/checkpoints/tom_train_new/tom_final.pth')\n",
    "    inference(tom_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running matlab\n",
      "Converting keypoints\n",
      "JNet Parsing\n",
      "WARNING:tensorflow:From ./LIP_JPPNet\\utils\\image_reader.py:146: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From D:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\tensorflow\\python\\training\\input.py:374: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From D:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\tensorflow\\python\\training\\input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From D:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\tensorflow\\python\\training\\input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From D:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From D:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From ./LIP_JPPNet\\utils\\image_reader.py:111: The name tf.read_file is deprecated. Please use tf.io.read_file instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Learning\\Fall2020\\Spring2021\\DeepLearning\\Project\\DLCode\\Virtual-Try-On-master\\LIP_JPPNet\\evaluate_parsing_JPPNet.py:35: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Learning\\Fall2020\\Spring2021\\DeepLearning\\Project\\DLCode\\Virtual-Try-On-master\\LIP_JPPNet\\evaluate_parsing_JPPNet.py:40: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ./LIP_JPPNet\\kaffe\\tensorflow\\network.py:45: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From ./LIP_JPPNet\\kaffe\\tensorflow\\network.py:99: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From ./LIP_JPPNet\\kaffe\\tensorflow\\network.py:197: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:180: calling expand_dims (from tensorflow.python.ops.array_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From D:\\Learning\\Fall2020\\Spring2021\\DeepLearning\\Project\\DLCode\\Virtual-Try-On-master\\LIP_JPPNet\\evaluate_parsing_JPPNet.py:109: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From D:\\Learning\\Fall2020\\Spring2021\\DeepLearning\\Project\\DLCode\\Virtual-Try-On-master\\LIP_JPPNet\\evaluate_parsing_JPPNet.py:113: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Learning\\Fall2020\\Spring2021\\DeepLearning\\Project\\DLCode\\Virtual-Try-On-master\\LIP_JPPNet\\evaluate_parsing_JPPNet.py:124: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "LIP_JPPNet/checkpoint/JPPNet-s2\n",
      "model_checkpoint_path: \"LIP_JPPNet/checkpoint/JPPNet-s2\\\\model.ckpt-205632\"\n",
      "all_model_checkpoint_paths: \"LIP_JPPNet/checkpoint/JPPNet-s2\\\\model.ckpt-205632\"\n",
      "\n",
      "WARNING:tensorflow:From D:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from LIP_JPPNet/checkpoint/JPPNet-s2\\model.ckpt-205632\n",
      "Restored model parameters from model.ckpt-205632\n",
      " [*] Load SUCCESS\n",
      "WARNING:tensorflow:From D:\\Learning\\Fall2020\\Spring2021\\DeepLearning\\Project\\DLCode\\Virtual-Try-On-master\\LIP_JPPNet\\evaluate_parsing_JPPNet.py:132: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "step 0\n",
      "data/test/image/guy.jpg\n",
      "GMM\n",
      "Start to test stage: GMM, named: gmm_traintest_new!\n",
      "initialization method [normal]\n",
      "initialization method [normal]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 5816) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mD:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7d9bcb2dc08e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_root_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data/raw_data/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_root_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data/test/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'guy.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tshirt.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-8d35f44812bd>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(source_root_dir, target_root_dir, imname, cname)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GMM\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mgmm_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gmm_traintest_new\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"GMM\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data/test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data/test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cp_vton/checkpoints/gmm_train_new/gmm_final.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgmm_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TOM\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mtom_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tom_test_new\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"TOM\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data/test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cp_vton/checkpoints/tom_train_new/tom_final.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Learning\\Fall2020\\Spring2021\\DeepLearning\\Project\\DLCode\\Virtual-Try-On-master\\cp_vton\\test.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0mload_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             \u001b[0mtest_gmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'TOM'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnetGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInstanceNorm2d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Learning\\Fall2020\\Spring2021\\DeepLearning\\Project\\DLCode\\Virtual-Try-On-master\\cp_vton\\test.py\u001b[0m in \u001b[0;36mtest_gmm\u001b[1;34m(opt, test_loader, model)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarp_mask_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0miter_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1182\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1146\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\Anaconda3\\envs\\rstudio\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    997\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 5816) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "main(source_root_dir='data/raw_data/', target_root_dir='data/test/', imname='guy.jpg', cname='tshirt.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
